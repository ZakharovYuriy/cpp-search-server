«Основы C++» вы будете разрабатывать ядро поисковой системы. В основном курсе вы разовьёте этот проект и сможете добавить его в своё портфолио. Проект будет большим.
Чтобы поисковая система искала, нужен поисковый запрос и документы, по которым идёт поиск. Допустим, кто-то нашёл на улице кота и запостил объявление об этом. Так в системе появился документ «Кот белый пушистый с синим ошейником найден в районе Перово в Москве телефон для связи 89222334455». Хозяин кота отправил запрос «Белый кот синий ошейник» и смог вернуть любимца. На подобных примерах вы будете изучать устройство поисковых систем и проектировать свою. Домашние животные — просто удобная иллюстрация. В общем случае поисковая система может работать с любыми запросами.

Хорошая поисковая система учитывает стоп-слова. Это союзы и предлоги, которые встречаются во многих документах и обычно не несут смысловой нагрузки. Если их исключить из обработки, результаты поиска станут более точными.

спринт1+++
В уроке «Специализация шаблонов» вы выполнили задание, в котором вернули методу FindTopDocuments возможность быть вызванным со статусом документа вместо лямбды.

спринт2+++
В уроке «Фреймворк и поисковая система» вы выполнили задание, где применили макросы ASSERT, ASSERT_HINT, ASSERT_EQUAL и ASSERT_EQUAL_HINT для проверки работы основных функций поисковой системы.

спринт3+++
В уроке «Обработка ошибок в поисковой системе» вы выполнили задание, где доработали класс SearchServer и научили поисковую систему обрабатывать ошибки.

спринт4+++
В уроке «Делим проект на файлы» вы выполнили задание, где разделили код поисковой системы на файлы.

спринт5 ++
В уроке «Дедупликатор документов» вы выполнили задание, где избавились от зеркал документов в своей поисковой системе. 

//спринт6+-
//спринт7---

спринт8+++
В уроках «Параллелим запросы к поисковой системе» и «Параллелим методы поисковой системы» первой темы, а также в уроке «Параллелим поиск документов» третьей темы вы выполнили задания по ускорению доступа к поисковой системе.













# Search server
Учебный проект С++17

# Описание программы
Это поисковая система потерянных животных. Для этого нужен поисковый запрос и документы, по которым идёт поиск. 
Допустим, кто-то нашёл на улице кота и запостил объявление об этом. Так в системе появился документ «Кот белый пушистый с синим ошейником найден в районе Перово в Москве телефон для связи 89222334455». Хозяин кота отправил запрос «Белый кот синий ошейник» и смог вернуть любимца.В общем случае поисковая система может работать с любыми запросами.

# Сборка при помощи Cmake
To build this project on linux you need:
1)If you don't have Cmake installed, install Cmake
2)If the "Debug" or "Release" folders are not created:
mkdir Debug
mkdir Release
3)Run the command for Debug and Release conf:
cmake -E chdir Debug/ cmake -G "Unix Makefiles" ../ -DCMAKE_BUILD_TYPE:STRING=Debug
cmake -E chdir Release/ cmake -G "Unix Makefiles" ../ -DCMAKE_BUILD_TYPE:STRING=Release
4)Build command:
cmake --build Debug/.
cmake --build Release/.

5)To **Run** program- go to the debug (cd Debug/) or release (cd Release/) folder and run:
./search_server

**ALL in one command(Release)**:
mkdir Release; cmake -E chdir Release/ cmake -G "Unix Makefiles" ../ -DCMAKE_BUILD_TYPE:STRING=Release && cmake --build Release/.

# Usage
  0. Установка и настройкка всех требуемых компонентов в среде разработки длля запуска приложения
  1. Вариант использования показан в main.cpp и test_example_functions.h
  2. запросы... 
  SearchServer(минус слова)
  void AddDocument(int document_id, std::string_view document, DocumentStatus status, const std::vector<int>& ratings);
  FindTopDocuments
  GetDocumentCount
  begin
  end
  MatchDocument
  GetWordFrequencies
  RemoveDocument
  
  
  
  	RUN_TEST(TestDocADD);
    RUN_TEST(TestExcludeStopWordsFromAddedDocumentContent);
	RUN_TEST(TestMinusWords);
	RUN_TEST(TestMatching);
	RUN_TEST(TestRelev);
	RUN_TEST(TestRating);
	RUN_TEST(TestPredictat);
	RUN_TEST(TestFindStatus);
	RUN_TEST(TestRelevCount);


# Системые требования:
  1. C++17(STL)
  2. GCC (MinG w64) 11.2.0
# Паны по доработке:
# Стек технологий:
  1. В проекте показано знание базовых принципов программирования С++:
     a. **Числа**, **строки**, **символы**, ввод/вывод данных в **консоли**, **условия**, **циклы**.
     b. Использованние базовых алгоритмов **<algorithm>**.
     b. Использованние **структур**, **классов**, **лямбда функций**, созданние **кортежей**
     c. Парсигн строк с выводом на экран
        Парсинг строк с сохранением в контейнере **vector**
        Выделение парсинга строки в функции для дальнейшего переиспользования (Работа с **функциями** , **Аргументы**, **Возврат результата**
        Парсинг запроса - **Ссылки**, **Константность**, **Глубокое копированине**  
        Обработка стоп-слов - контейнер **set**
	Добавление документов в поисковую систему, Поиск документов, Вычисление релевантности найденных документов - контейнеры: **pair**, **map** 
     d. Использование **Шаблонов** и **Специализация шаблонов**
     e. Создание и использование макросов
     g.	**Перегрузка** операторов
     h.	Обработка **исключений**
     i.	Применение класса **optional**
     g.	**Итераторы**
     k. Рекурсия
     k. **Стек**, **Дек**
     k.	Работа с стандартными потоками ввода вывода
     	Работа с файловыми потоками
     k.	**Статическое**, **Автоматическое** и **Динамическое** размещение обьектов в памяти
     k. Паралелная работа при помощи библтотеки **<execution>**
     k. Scan-алгоритмы
     k. Асинхронные вычисления при помощи библтотеки **<future>**
     k.	Защита от состояния гонки: **mutex**, **lock_guard**, **atomic**-типы

  2. Вычисение term frequency, «частота термина» и inverse document frequency, «обратная частота документа»
  3. **Юнит тестирование**
  4. Декомпозиция и отладка
  5. Создание многофайловых проектов
  6. Профилирование
  7. Оценка сложности программы
  8. MapReduce — концепция, при которой алгоритм разбивается на две стадии:
независимая фильтрация и преобразование отдельных элементов (map или transform);
группировка результатов предыдущей стадии (reduce).

#Описание проведенных тестов:
итог4спринта
##ManyRequests:
Когда запросов приходит слишком много, их обработка занимает время. Запросы, ожидающие обработки, могут просто «‎посидеть»‎ в очереди и подождать, пока сервис-обработчик доберётся до них.
Для хранения только нужных запросов. Например, вы хотите знать, какие запросы пользователи отправляли на поисковый сервер. Но важны только актуальные запросы за последние сутки. То есть вам интересно время отправки. Хранить запросы старше суток не требуется.
Каждую минуту приходит один запрос от пользователя. То есть максимальное количество запросов, которые надо хранить, — это количество минут в сутках (1440). Появление 1441 запроса будет означать, что сутки прошли, первый запрос прошлых суток нам больше не интересен и может быть удалён. Для реализации такого механизма удобно использовать deque. Новый запрос легко вставится в конец, а устаревший запрос удалится из начала. 

в4 спринте
##Split the results into pages:
Итераторы можно применять далеко не в самых очевидных случаях. Представьте, что ваш поисковый сервер содержит сотни тысяч или даже миллионы документов. Из них тысячи подходят под запрос пользователя. В этом случае вывод всех запросов на экран разом не будет хорошей идеей. Нужно разбивать результаты на страницы.
Пригодятся итераторы. Предположим, у нас есть контейнер. Тогда одна страница — это некий диапазон определённого размера из этого контейнера. Первый элемент входит в страницу, а последний — нет. Зато последний будет первым элементом на следующей странице. То есть можем получить контейнер с результатами, а потом на основе него создать вектор диапазонов, где диапазон будет просто парой итераторов. Первый итератор укажет на начало страницы, а второй — на её конец.
Отвечать за разделение по страницам может новый класс. Назовём его Paginator. Пусть это будет класс-шаблон. Он работает так же, как метод-шаблон, только при создании объекта такого класса надо указать тип. С подобными классами вы уже встречались. Например, все классы контейнеров — шаблоны. Синтаксис будет выглядеть так:


первый спринт
##ComputeTfIdfs
Реализуйте шаблонную функцию ComputeTfIdfs, которая вычисляет TF-IDF заданного слова для каждого документа из набора.
Первый параметр documents — контейнер документов. Циклом for (const auto& document : documents) можно перебрать все документы в нём, а в каждом документе — все слова. Тип слова, документа и набора документов может быть произвольным — ваша функция должна быть готова к любым, если есть возможность итерирования. Гарантируется, что и набор документов, и каждый отдельный документ имеют методы begin, end и size. Например, документом может быть строка, а словом — символ.
Второй параметр term — слово, у которого нужно вычислить TF-IDF. Его тип совпадает с типом слов, которые получаются при итерировании по документу.
Функция должна вернуть вектор вещественных чисел, который совпадает по длине с количеством документов. В первом элементе должен лежать TF-IDF слова term для первого документа, в последнем элементе — TF-IDF слова term для последнего документа.
Напоминаем, что TF-IDF — это произведение TF и IDF. TF слова term в документе — доля слов документа, совпадающих с term. IDF вычисляется для слова независимо от конкретного документа и равен логарифму (функция log из <cmath>) от documents.size() / document_freq, где знаменатель — это количество документов, содержащих term.


первый спринт
##SpecializationOfTemplates
Научите метод FindTopDocuments вместо статуса принимать более универсальный фильтр документов — функцию-предикат. Она в свою очередь принимает id документа, статус и рейтинг и возвращает bool. Фильтрация документов должна производиться до отсечения топа из пяти штук.
Вызов FindTopDocuments без второго аргумента должен осуществлять поиск только по актуальным документам.

Верните методу FindTopDocuments возможность быть вызванным со статусом документа вместо лямбды.



итог 3 спринта
#Throw an exception
Конструкторы класса SearchServer должны выбрасывать исключение invalid_argument, если любое из переданных стоп-слов содержит недопустимые символы, то есть символы с кодами от 0 до 31. Такого требования не было в предыдущих заданиях, так как известные вам на тот момент способы обработки ошибок не позволяли эффективно решить эту задачу в конструкторе.
Метод AddDocument больше не должен использовать возврат значения типа bool для сообщения об успехе или ошибке. Вместо этого он должен выбрасывать исключение invalid_argument в следующих ситуациях:
Попытка добавить документ с отрицательным id;
Попытка добавить документ c id ранее добавленного документа;
Наличие недопустимых символов (с кодами от 0 до 31) в тексте добавляемого документа.
Методы FindDocument вместо возврата optional<vector<Document>> должны возвращать vector<Document> и выбрасывать исключение invalid_argument в следующих ситуациях:
В словах поискового запроса есть недопустимые символы с кодами от 0 до 31;
Наличие более чем одного минуса перед словами, которых не должно быть в искомых документах, например, пушистый --кот. В середине слов минусы разрешаются, например: иван-чай.
Отсутствие текста после символа «минус»: в поисковом запросе: "пушистый -".
Метод MatchDocument должен возвращать tuple<vector<string>, DocumentStatus>, выбрасывая исключение invalid_argument в тех же ситуациях, что и метод FindDocument.
Метод GetDocumentId должен выбрасывать исключение out_of_range, если индекс переданного документа выходит за пределы допустимого диапазона (0; количество документов).

##Итераторы BEGIN END
Расширьте поисковый сервер, добавив в него дополнительные методы.
Откажитесь от метода GetDocumentId(int index) и вместо него определите методы begin и end. Они вернут итераторы. Итератор даст доступ к id всех документов, хранящихся в поисковом сервере. Вы можете не разрабатывать собственный итератор, а применить готовый константный итератор удобного контейнера.
Если begin и end определены корректно, появится возможность использовать упрощённую форму for с поисковым сервером:
       

##Разработайте метод получения частот слов по id документа:
 const map<string, double>& GetWordFrequencies(int document_id) const;
  
Если документа не существует, возвратите ссылку на пустой map.
Разработайте метод удаления документов из поискового сервера
 void RemoveDocument(int document_id);
 
##Fункцию поиска и удаления дубликатов: 
void RemoveDuplicates(SearchServer& search_server);
Поисковые системы сталкиваются с проблемой — зеркалами. Это копии сайта. Их количество в Интернете может достигать десятков или сотен. Чтобы первые страницы поисковой выдачи не состояли из копий одного и того же сайта, нужно разработать дедупликатор. Он удаляет копии из поискового сервера. Но поскольку функция удаления пока не предусмотрена, вам предстоит расширить поисковый сервер.
 Дубликатами считаются документы, у которых наборы встречающихся слов совпадают. Совпадение частот необязательно. Порядок слов неважен, а стоп-слова игнорируются. Функция должна использовать только доступные к этому моменту методы поискового сервера.
При обнаружении дублирующихся документов функция должна удалить документ с большим id из поискового сервера, и при этом сообщить id удалённого документа в соответствии с форматом выходных данных, приведённым ниже.


##Напишите функцию ProcessQueries, 
распараллеливающую обработку нескольких запросов к поисковой системе.
функция ProcessQueriesJoined должна, подобно функции ProcessQueries, распараллеливать обработку нескольких запросов к поисковой системе, но возвращать набор документов в плоском виде.

Часто действительно достаточно распараллелить обработку нескольких запросов — и дело в шляпе. Но бывает и другая ситуация: один запрос обрабатывается слишком долго, и распараллелить нужно его реализацию.
Реализуйте многопоточную версию метода RemoveDocument в дополнение к однопоточной.
многопоточную версию метода MatchDocument в дополнение к однопоточной
Реализуйте многопоточную версию метода FindTopDocuments в дополнение к однопоточной


##Перейдите сиспользования класса string на string_view там, где это возможно, и тем самым ускорьте программу.
Следующие методы теперь должны позволять принять string_view вместо строки:
конструктор;
AddDocument;
FindTopDocuments;
MatchDocument.
Эти методы должны возвращать string_view вместо строк:
MatchDocument;
GetWordFrequencies.




#1 СПРНТ
int main() {
    SearchServer search_server;
    search_server.SetStopWords("и в на"s);

    search_server.AddDocument(0, "белый кот и модный ошейник"s,        DocumentStatus::ACTUAL, {8, -3});
    search_server.AddDocument(1, "пушистый кот пушистый хвост"s,       DocumentStatus::ACTUAL, {7, 2, 7});
    search_server.AddDocument(2, "ухоженный пёс выразительные глаза"s, DocumentStatus::ACTUAL, {5, -12, 2, 1});
    search_server.AddDocument(3, "ухоженный скворец евгений"s,         DocumentStatus::BANNED, {9});

    cout << "ACTUAL by default:"s << endl;
    for (const Document& document : search_server.FindTopDocuments("пушистый ухоженный кот"s)) {
        PrintDocument(document);
    }

    cout << "BANNED:"s << endl;
    for (const Document& document : search_server.FindTopDocuments("пушистый ухоженный кот"s, DocumentStatus::BANNED)) {
        PrintDocument(document);
    }

    cout << "Even ids:"s << endl;
    for (const Document& document : search_server.FindTopDocuments("пушистый ухоженный кот"s, [](int document_id, DocumentStatus status, int rating) { return document_id % 2 == 0; })) {
        PrintDocument(document);
    }

    return 0;
} 

Вывод
ACTUAL by default:
{ document_id = 1, relevance = 0.866434, rating = 5 }
{ document_id = 0, relevance = 0.173287, rating = 2 }
{ document_id = 2, relevance = 0.173287, rating = -1 }
BANNED:
{ document_id = 3, relevance = 0.231049, rating = 9 }
Even ids:
{ document_id = 0, relevance = 0.173287, rating = 2 }
{ document_id = 2, relevance = 0.173287, rating = -1 } 


#2 СПРНТ
В уроке «Фреймворк и поисковая система» вы выполнили задание, где применили макросы ASSERT, ASSERT_HINT, ASSERT_EQUAL и ASSERT_EQUAL_HINT для проверки работы основных функций поисковой системы.

Это задание — итоговый проект второго спринта. Вы будете сдавать его на проверку через репозиторий на GitHub. А пока сохраните решение в своей IDE.
Примените макросы ASSERT, ASSERT_HINT, ASSERT_EQUAL и ASSERT_EQUAL_HINT для проверки работы основных функций поисковой системы, таких как:
Добавление документов. Добавленный документ должен находиться по поисковому запросу, который содержит слова из документа.
Поддержка стоп-слов. Стоп-слова исключаются из текста документов.
Поддержка минус-слов. Документы, содержащие минус-слова из поискового запроса, не должны включаться в результаты поиска.
Соответствие документов поисковому запросу. При этом должны быть возвращены все слова из поискового запроса, присутствующие в документе. Если есть соответствие хотя бы по одному минус-слову, должен возвращаться пустой список слов.
Сортировка найденных документов по релевантности. Возвращаемые при поиске документов результаты должны быть отсортированы в порядке убывания релевантности.
Вычисление рейтинга документов. Рейтинг добавленного документа равен среднему арифметическому оценок документа.
Фильтрация результатов поиска с использованием предиката, задаваемого пользователем.
Поиск документов, имеющих заданный статус.
Корректное вычисление релевантности найденных документов.
Как будет происходить проверка этого задания
Разработанные вами тесты должны иметь точку входа, заданную функцией TestSearchServer. Код поисковой системы должен успешно проходить ваши тесты. Тренажёр проверит работу тестов на нескольких реализациях класса SearchServer. Одна из реализаций будет корректной, в других будут ошибки в логике работы класса. Задача считается решённой при выполнении следующих условий:
Корректная реализация класса SearchServer успешно проходит тесты, которые вы разработали;
Ваши тесты выявляют не менее 50% некорректных реализаций класса SearchServer;
Ваши тесты используют макросы фреймворка вместо стандартного макроса assert.
Тренажёр ожидает, что ваша реализация класса SearchServer будет содержать следующие публичные методы.

#3 СПРНТ
В уроке «Обработка ошибок в поисковой системе» вы выполнили задание, где доработали класс SearchServer и научили поисковую систему обрабатывать ошибки.
Это задание — итоговый проект третьего спринта. Вы будете сдавать его на проверку через репозиторий на GitHub.
Доработайте класс SearchServer. Примените механизм исключений и реализуйте в SearchServer обработку проблем.
Конструкторы класса SearchServer должны выбрасывать исключение invalid_argument, если любое из переданных стоп-слов содержит недопустимые символы, то есть символы с кодами от 0 до 31. Такого требования не было в предыдущих заданиях, так как известные вам на тот момент способы обработки ошибок не позволяли эффективно решить эту задачу в конструкторе.
Метод AddDocument больше не должен использовать возврат значения типа bool для сообщения об успехе или ошибке. Вместо этого он должен выбрасывать исключение invalid_argument в следующих ситуациях:
Попытка добавить документ с отрицательным id;
Попытка добавить документ c id ранее добавленного документа;
Наличие недопустимых символов (с кодами от 0 до 31) в тексте добавляемого документа.
Методы FindDocument вместо возврата optional<vector<Document>> должны возвращать vector<Document> и выбрасывать исключение invalid_argument в следующих ситуациях:
В словах поискового запроса есть недопустимые символы с кодами от 0 до 31;
Наличие более чем одного минуса перед словами, которых не должно быть в искомых документах, например, пушистый --кот. В середине слов минусы разрешаются, например: иван-чай.
Отсутствие текста после символа «минус»: в поисковом запросе: "пушистый -".
Метод MatchDocument должен возвращать tuple<vector<string>, DocumentStatus>, выбрасывая исключение invalid_argument в тех же ситуациях, что и метод FindDocument.
Метод GetDocumentId должен выбрасывать исключение out_of_range, если индекс переданного документа выходит за пределы допустимого диапазона (0; количество документов).

#4 СПРНТ
В прошлом уроке вы узнали, что для упорядочивания часто поступающих запросов их организуют в очередь. Это полезно в нескольких случаях.
***************************************
Когда запросов приходит слишком много, их обработка занимает время. Запросы, ожидающие обработки, могут просто «‎посидеть»‎ в очереди и подождать, пока сервис-обработчик доберётся до них.
Для хранения только нужных запросов. Например, вы хотите знать, какие запросы пользователи отправляли на поисковый сервер. Но важны только актуальные запросы за последние сутки. То есть вам интересно время отправки. Хранить запросы старше суток не требуется.
Каждую минуту приходит один запрос от пользователя. То есть максимальное количество запросов, которые надо хранить, — это количество минут в сутках (1440). Появление 1441 запроса будет означать, что сутки прошли, первый запрос прошлых суток нам больше не интересен и может быть удалён. Для реализации такого механизма удобно использовать deque. Новый запрос легко вставится в конец, а устаревший запрос удалится из начала.
*****************************************

Это задание — итоговый проект четвёртого спринта. Вы будете сдавать его на проверку через репозиторий на GitHub.
В уроке «Очередь запросов» вы сделали задание и сохранили решение себе. Сейчас это решение вам понадобится.
Код вашей поисковой системы находится в одном файле. Разделите код на файлы, сохраняя функциональность. Каждый файл должен иметь понятное название и логически объединять в себе функции, классы и переменные.

#5 СПРНТ
В уроке «Дедупликатор документов» вы выполнили задание, где избавились от зеркал документов в своей поисковой системе. Это задание — итоговый проект пятого спринта. Чтобы сдать проект на проверку, нужен ваш закрытый репозиторий на GitHub.

Это задание — итоговый проект пятого спринта. Вы будете сдавать его на проверку через репозиторий на GitHub. Не забудьте сохранить верное решение.
Расширьте поисковый сервер, добавив в него дополнительные методы.
Откажитесь от метода GetDocumentId(int index) и вместо него определите методы begin и end. Они вернут итераторы. Итератор даст доступ к id всех документов, хранящихся в поисковом сервере. Вы можете не разрабатывать собственный итератор, а применить готовый константный итератор удобного контейнера.
Если begin и end определены корректно, появится возможность использовать упрощённую форму for с поисковым сервером:
 SearchServer search_server;

 for (const int document_id : search_server) {
     // ...
 }
  
Разработайте метод получения частот слов по id документа:
 const map<string, double>& GetWordFrequencies(int document_id) const;
  
Если документа не существует, возвратите ссылку на пустой map.
Разработайте метод удаления документов из поискового сервера
 void RemoveDocument(int document_id);
  
Вне класса сервера разработайте функцию поиска и удаления дубликатов:
 void RemoveDuplicates(SearchServer& search_server);
  
Дубликатами считаются документы, у которых наборы встречающихся слов совпадают. Совпадение частот необязательно. Порядок слов неважен, а стоп-слова игнорируются. Функция должна использовать только доступные к этому моменту методы поискового сервера.
При обнаружении дублирующихся документов функция должна удалить документ с большим id из поискового сервера, и при этом сообщить id удалённого документа в соответствии с форматом выходных данных, приведённым ниже.
Будьте аккуратны, если функция RemoveDuplicates проходит циклом по поисковому серверу так:
void RemoveDuplicates(SearchServer& search_server) {
    ...
    for (const int document_id : search_server) {
        ...
    }
    ...
} 
В подобном случае удалять документы внутри цикла нельзя — это может привести к невалидности внутреннего итератора.
Все реализации должны быть эффективными. Если NN — общее количество документов, а WW — количество слов во всех документах, то:
сложность GetWordFrequencies должна быть O(\log N)O(logN);
сложность RemoveDocument должна быть O(w(\log N+\log W))O(w(logN+logW)), где ww — количество слов в удаляемом документе;
сложность begin и end — O(1)O(1);
сложность RemoveDuplicates должна быть O(wN(\log N+\log W))O(wN(logN+logW)), где ww — максимальное количество слов в документе.
В этом задании может потребоваться рефакторинг вашего кода. Например, замена одного вида контейнера на другой или введение нового индекса.
Вам предстоит оценить сложность разрабатываемых алгоритмов, чтобы знать, что они достаточно быстрые.
Формат выходных данных
Функция RemoveDuplicates должна для каждого удаляемого документа вывести в cout сообщение в формате Found duplicate document id N, где вместо N следует подставить id удаляемого документа.
Ограничения
Сохраните корректную и быструю работу всех методов кроме GetDocumentId.
Что отправлять на проверку
Загрузите полный код поискового сервера и вспомогательных функций. Код нужно разбить на файлы. Функция main при проверке будет игнорироваться.
Как будет тестироваться ваш код
Будет проверено, что:
вы не изменили работу методов и функций, которые не описаны в условии,
вы реализовали требуемые методы и функцию RemoveDuplicates,
реализованные методы работают достаточно быстро и их сложность соответствует условию.


#8 СПРИНТ
Реализуйте многопоточную версию метода FindTopDocuments в дополнение к однопоточной. Это нужно сделать для всех перегрузок метода: без фильтраций, с фильтрацией по статусу и по произвольному предикату.

