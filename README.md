# Search server
Учебный проект С++17

# Program Description
Это поисковая система потерянных животных. Для этого нужен поисковый запрос и документы, по которым идёт поиск. 
Допустим, кто-то нашёл на улице кота и запостил объявление об этом. Так в системе появился документ «Кот белый пушистый с синим ошейником найден в районе Перово в Москве телефон для связи 89222334455». Хозяин кота отправил запрос «Белый кот синий ошейник» и смог вернуть любимца.В общем случае поисковая система может работать с любыми запросами.

# Build a Project using Cmake
To build this project on linux you need:<br>
1)If you don't have Cmake installed, install Cmake<br>
2)If the "Debug" or "Release" folders are not created:<br>

```
mkdir Debug
mkdir Release
```
3)Run the command for Debug and Release conf:<br>

```
cmake -E chdir Debug/ cmake -G "Unix Makefiles" ../ -DCMAKE_BUILD_TYPE:STRING=Debug
cmake -E chdir Release/ cmake -G "Unix Makefiles" ../ -DCMAKE_BUILD_TYPE:STRING=Release
```
4)Build command:<br>

```
cmake --build Debug/.
cmake --build Release/.
```

5)To **Run** program- go to the debug (cd Debug/) or release (cd Release/) folder and run:<br>

```
./search_server
```

**ALL in one command(Release)**:<br>

```
mkdir Release; cmake -E chdir Release/ cmake -G "Unix Makefiles" ../ -DCMAKE_BUILD_TYPE:STRING=Release && cmake --build Release/.
```

# Usage
###Перед тем как начать:
  0. Установка и настройкка всех требуемых компонентов в среде разработки длля запуска приложения
  1. Вариант использования показан в main.cpp и test_example_functions.h 

##Описание возможностей:

###Ядром поисковой системы является класс:  SearchServer
 Метдоы класса SearchServer:
 
- Конструктор принимает строку- Стоп-слова например: `"in at and"s` <br>
  Стоп-слово в запросе не учитывается при поиске.
  
-  Добавление документов в поисковую систему.
  `void AddDocument(int document_id, string_view document,DocumentStatus status, const vector<int> &ratings);`  
  document - строка вида: `"funny pet and nasty -rat"s`  
  где *"funny pet nasty"* - слова по которым будет идти поиcк
  *"and"* - стоп слово, указанное в конструкторе SearchServer
  *"-rat"* - миус слово<br>
  Минус-слова исключают из результатов поиска документы, содержащие такие слова.<br>
  Возможный `DocumentStatus: ACTUAL, IRRELEVANT, BANNED, REMOVED` <br>
  ratings - Каждый документ на входе имеет набор оценок пользователей. Первая цифра — это количество оценок<br>
  например:*{4 5 -12 2 1}*;<br>
  
- Поиск document в поисковом сервере и ранжирование по TF-IDF<br>
  Есть 6 способов вызова функции 3 однопоточные и 3 многопоточнные ExecutionPolicy  
  `FindTopDocuments (ExecutionPolicy,query)`  
  `FindTopDocuments (ExecutionPolicy,query,DocumentStatus)`  
  `FindTopDocuments (ExecutionPolicy,query,DocumentPredicate)`  
  `FindTopDocuments (query)/FindTopDocuments (query,DocumentStatus)`  
  `FindTopDocuments (query,DocumentPredicate)`<br>
  возвращает vector<Document> подходящих по **query**<br>
  Полезность слов оценивают понятием inverse document frequency или IDF. <br>
  Эта величина — свойство слова, а не документа. <br>
  Чем в большем количестве документов есть слово, тем ниже IDF.<br>
  Выше располагать документы, где искомое слово встречается более одного раза. <br>
  Здесь нужно рассчитать term frequency или TF.<br>
  Для конкретного слова и конкретного документа это доля, которую данное слово занимает среди всех.<br>
  
 - `GetDocumentCount()` - возвращает количество документов в поисковом сервере<br>
  
 - `begin и end` - Они вернут итераторы. Итератор даст доступ к id всех документов, хранящихся в поисковом сервере.<br>
  
- `tuple<std::vector<std::string_view>, DocumentStatus> MatchDocument(raw_query, document_id)`<br>
  Возвращает:Первый объект — это вектор слов запроса, которые нашлись в документе document_id, <br>
  а второй объект — статус документа<br>

- Метод получения частот слов по id документа:<br>
 `map<string, double> GetWordFrequencies(document_id)`<br>

- Удаление документа из поискового сервера <br>
  `RemoveDocument(document_id)`  
  `RemoveDocument(ExecutionPolicy,document_id)`  
  `RemoveDocument(ExecutionPolicy, document_id)`
  
###Дополнительный фуннкционал:
- Вывод в поток станндартного ввода/вывода информацию о докукменте<br>
  `PrintDocument(document)`<br>
  `PrintMatchDocumentResult(document_id,vector<std::string_view> &words, DocumentStatus)`<br>

- Класс `LogDuration` - позволяет проводить профилирование<br>

- `Paginate()` - Позволяет разбивать результаты на страницы<br>

- `RemoveDuplicates(SearchServer)` - позволяет избавиться от дублирующихся документов<br>

- А так же другие функции, обеспечивающие обработку входных данных.<br>

# Системые требования:
  1. C++17(STL)
  2. GCC (MinG w64) 11.2.0  
  
# Паны по доработке:
1. Добавить UI
2. Добавить возможность чтения документов из файлов
3. Добавить поддержку JSON запросов/ответов

# Стек технологий:
  1. В проекте показано знание базовых принципов программирования С++:<br>
     a. **Числа**, **строки**, **символы**, ввод/вывод данных в **консоли**, **условия**, **циклы**.<br>
     b. Использованние базовых алгоритмов **<algorithm>**.<br>
     с. Использованние **структур**, **классов**, **лямбда функций**, созданние **кортежей**<br>
     d. Парсигн строк с выводом на экран<br>
        Парсинг строк с сохранением в контейнере **vector**<br>
        Выделение парсинга строки в функции для дальнейшего переиспользования <br>
        (Работа с **функциями** , **Аргументы**, **Возврат результата**<br>
        Парсинг запроса - **Ссылки**, **Константность**, **Глубокое копированине**  <br>
        Обработка стоп-слов - контейнер **set**<br>
        Добавление документов в поисковую систему, Поиск документов,<br>
        Вычисление релевантности найденных документов - контейнеры: **pair**, **map** <br>
     e. Использование **Шаблонов** и **Специализация шаблонов**<br>
     f. Создание и использование макросов<br>
     g.	**Перегрузка** операторов<br>
     h.	Обработка **исключений**<br>
     i.	Применение класса **optional**<br>
     g.	**Итераторы**<br>
     k. Рекурсия<br>
     l. **Стек**, **Дек**<br>
     m.	Работа с стандартными потоками ввода вывода<br>
     	Работа с файловыми потоками<br>
     n.	**Статическое**, **Автоматическое** и **Динамическое** размещение обьектов в памяти<br>
     o. Паралелная работа при помощи библтотеки **<execution>**<br>
     p. Scan-алгоритмы<br>
     q. Асинхронные вычисления при помощи библтотеки **<future>**<br>
     r.	Защита от состояния гонки: **mutex**, **lock_guard**, **atomic**-типы<br>

  2. Вычисение term frequency и inverse document frequency
  3. **Юнит тестирование**
  4. Декомпозиция и отладка
  5. Создание многофайловых проектов
  6. Профилирование
  7. Оценка сложности программы
  8. MapReduce — концепция, при которой алгоритм разбивается на две стадии:<br>
	независимая фильтрация и преобразование отдельных элементов (map или transform);<br>
	группировка результатов предыдущей стадии (reduce).<br>

#Описание проведенных тестов:
##ManyRequests
Когда запросов приходит слишком много, их обработка занимает время. Запросы, ожидающие обработки, могут просто «‎посидеть»‎ в очереди и подождать, пока сервис-обработчик доберётся до них.
Для хранения только нужных запросов. Например, вы хотите знать, какие запросы пользователи отправляли на поисковый сервер. Но важны только актуальные запросы за последние сутки. То есть вам интересно время отправки. Хранить запросы старше суток не требуется.
Каждую минуту приходит один запрос от пользователя. То есть максимальное количество запросов, которые надо хранить, — это количество минут в сутках (1440). Появление 1441 запроса будет означать, что сутки прошли, первый запрос прошлых суток нам больше не интересен и может быть удалён. Для реализации такого механизма удобно использовать deque. Новый запрос легко вставится в конец, а устаревший запрос удалится из начала. 

##Split the results into pages
Итераторы можно применять далеко не в самых очевидных случаях. Представьте, что поисковый сервер содержит сотни тысяч или даже миллионы документов. Из них тысячи подходят под запрос пользователя. В этом случае вывод всех запросов на экран разом не будет хорошей идеей. Нужно разбивать результаты на страницы.
Пригодятся итераторы. Предположим, у нас есть контейнер. Тогда одна страница — это некий диапазон определённого размера из этого контейнера. Первый элемент входит в страницу, а последний — нет. Зато последний будет первым элементом на следующей странице. То есть можем получить контейнер с результатами, а потом на основе него создать вектор диапазонов, где диапазон будет просто парой итераторов. Первый итератор укажет на начало страницы, а второй — на её конец.
Отвечать за разделение по страницам может класс Paginator.

##Specialization of templates
Метод FindTopDocuments может вместо статуса принимать более универсальный фильтр документов — функцию-предикат. Она в свою очередь принимает id документа, статус и рейтинг и возвращает bool. Фильтрация документов должна производиться до отсечения топа из пяти штук.
Вызов FindTopDocuments без второго аргумента должен осуществлять поиск только по актуальным документам.

##Fункция поиска и удаления дубликатов: 
Поисковые системы сталкиваются с проблемой — зеркалами. Это копии сайта. Их количество в Интернете может достигать десятков или сотен. Чтобы первые страницы поисковой выдачи не состояли из копий одного и того же сайта, нужно разработать дедупликатор. Он удаляет копии из поискового сервера. Дубликатами считаются документы, у которых наборы встречающихся слов совпадают. Совпадение частот необязательно. Порядок слов неважен, а стоп-слова игнорируются. Функция использует только доступные к этому моменту методы поискового сервера.
При обнаружении дублирующихся документов функция должна удалить документ с большим id из поискового сервера, и при этом сообщить id удалённого документа в соответствии с форматом выходных данных, приведённым ниже.

##Тесты многопоточнности 
Функция ProcessQueries распараллеливает обработку нескольких запросов к поисковой системе.
функция ProcessQueriesJoined, подобно функции ProcessQueries, распараллеливает обработку нескольких запросов к поисковой системе, но возвращает набор документов в плоском виде.
Часто действительно достаточно распараллелить обработку нескольких запросов — и дело в шляпе. Но бывает и другая ситуация: один запрос обрабатывается слишком долго, и распараллелить нужно его реализацию.
Многопоточная версия метода RemoveDocument в дополнение к однопоточной.
Многопоточная версия метода MatchDocument в дополнение к однопоточной.
Многопоточная версия метода FindTopDocuments в дополнение к однопоточной.

#Особенности
###Throw an exception
Конструкторы класса SearchServer выбрасывают исключение invalid_argument, если любое из переданных стоп-слов содержит недопустимые символы, то есть символы с кодами от 0 до 31.
Метод AddDocument выбрасывает исключение invalid_argument в следующих ситуациях:
	Попытка добавить документ с отрицательным id;
	Попытка добавить документ c id ранее добавленного документа;
	Наличие недопустимых символов (с кодами от 0 до 31) в тексте добавляемого документа.
Методы FindDocument выбрасывает исключение invalid_argument в следующих ситуациях:
	В словах поискового запроса есть недопустимые символы с кодами от 0 до 31;
	Наличие более чем одного минуса перед словами, которых не должно быть в искомых документах, например, пушистый --кот. В середине слов минусы разрешаются, например: иван-чай.
	Отсутствие текста после символа «минус»: в поисковом запросе: "пушистый -".
Метод MatchDocument выбрасывает исключение invalid_argument в тех же ситуациях, что и метод FindDocument.
Метод GetDocumentId выбрасывает исключение out_of_range, если индекс переданного документа выходит за пределы допустимого диапазона (0; количество документов).

###Итераторы BEGIN END
Определены методы begin и end. Они вернут итераторы. Итератор даст доступ к id всех документов, хранящихся в поисковом сервере. 

